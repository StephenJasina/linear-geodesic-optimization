{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computations in this notebook are based on [this repo](https://github.com/Ghandisanaa/network_datasets)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we grab some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mpmath\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from linear_geodesic_optimization.data import input_network\n",
    "from linear_geodesic_optimization.data import utility\n",
    "from linear_geodesic_optimization.plot import get_network_plot\n",
    "\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we grab an actual network. In this example, we base it off of the toy example from the SIGCOMM paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes_file_path = os.path.join('..', 'data', 'toy', 'generated', 'probes.csv')\n",
    "latencies_file_path = os.path.join('..', 'data', 'toy', 'generated', 'connectivity.csv')\n",
    "\n",
    "graph = input_network.get_graph_from_paths(\n",
    "    probes_file_path, latencies_file_path,\n",
    "    epsilon=10.,\n",
    "    # clustering_distance=500000.,\n",
    "    ricci_curvature_alpha=0.9999\n",
    ")\n",
    "\n",
    "# Store vertex information. Vertices are indices (integers), and labels\n",
    "# are human-readable strings\n",
    "n_vertices = len(graph.nodes)\n",
    "vertex_to_label = list(graph.nodes)\n",
    "label_to_vertex = {\n",
    "    label: vertex\n",
    "    for vertex, label in enumerate(vertex_to_label)\n",
    "}\n",
    "\n",
    "# Store edge information. Edges are indices (integers), and labels are\n",
    "# their corresponding (vertex_source, vertex_destination) pairs. Note\n",
    "# that each edge is stored twice (once for each orientation)\n",
    "n_edges = len(graph.edges)\n",
    "edge_to_label = [\n",
    "    label\n",
    "    for i, (u, v) in enumerate(graph.edges)\n",
    "    for label in [\n",
    "        (label_to_vertex[u], label_to_vertex[v]),\n",
    "        (label_to_vertex[v], label_to_vertex[u])\n",
    "    ]\n",
    "]\n",
    "label_to_edge = {\n",
    "    label: edge\n",
    "    for edge, label in enumerate(edge_to_label)\n",
    "}\n",
    "\n",
    "# Compute the shortest paths. These are stored as a dict of lists of\n",
    "# edges, where the keys are pairs of vertices\n",
    "all_pairs_shortest_paths = {\n",
    "    (label_to_vertex[u], label_to_vertex[v]): [\n",
    "        (label_to_edge[label_to_vertex[x], label_to_vertex[y]])\n",
    "        for x, y in itertools.pairwise(shortest_path)\n",
    "    ]\n",
    "    for u, shortest_paths in dict(nx.all_pairs_shortest_path(graph)).items()\n",
    "    for v, shortest_path in shortest_paths.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_network_plot(graph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_states_discrete(initial_state, transition_matrix):\n",
    "    \"\"\"Run a Markov chain.\"\"\"\n",
    "    state = initial_state\n",
    "    n_states = np.shape(transition_matrix)[0]\n",
    "    yield state\n",
    "    while True:\n",
    "        state = rng.choice(n_states, p=transition_matrix[state, :])\n",
    "        yield state\n",
    "\n",
    "def generate_states_continuous(initial_state, q_matrix):\n",
    "    \"\"\"Run a Markov chain.\"\"\"\n",
    "    state = initial_state\n",
    "    n_states = np.shape(q_matrix)[0]\n",
    "    rates = -np.diag(q_matrix)\n",
    "    stochastic_matrix = q_matrix / rates.reshape((-1, 1))\n",
    "    np.fill_diagonal(stochastic_matrix, 0.)\n",
    "    time_remaining = rng.exponential(1 / rates[state])\n",
    "    while True:\n",
    "        while time_remaining >= 0.:\n",
    "            yield state\n",
    "            time_remaining -= 1.\n",
    "        state = rng.choice(n_states, p=stochastic_matrix[state, :])\n",
    "        time_remaining += rng.exponential(1 / rates[state])\n",
    "\n",
    "def generate_relative_rates(\n",
    "    horizon, n_nodes, initial_state, q_matrix, rates_per_state\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a horizon (total number of iterations), the number of nodes to\n",
    "    get the rates for, the initial state, transition matrix, and the\n",
    "    rates in a given state, generate a matrix such that:\n",
    "    * The matrix has `n_nodes` rows and `horizon` columns\n",
    "    * The maximum of the matrix is 1\n",
    "    * For a node in the state `s`, the entry is proportional to\n",
    "      `rates_per_state[s]`\n",
    "    \"\"\"\n",
    "    # First, generate the non-normalized matrix of rates\n",
    "    rates = np.zeros((n_nodes, horizon))\n",
    "    for node in range(n_nodes):\n",
    "        rates[node, :] = np.array([\n",
    "            rates_per_state[state]\n",
    "            for state in itertools.islice(\n",
    "                generate_states_continuous(initial_state, q_matrix),\n",
    "                horizon\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    # Now normalize\n",
    "    return rates / np.amax(rates)\n",
    "\n",
    "def generate_relative_rates_pathwise(\n",
    "    horizon, n_nodes, edges, shortest_paths, initial_state, q_matrix, rates_per_state\n",
    "):\n",
    "    rates = np.zeros((n_nodes, horizon))\n",
    "    for s in range(n_nodes):\n",
    "        for d in range(n_nodes):\n",
    "            if s == d:\n",
    "                continue\n",
    "\n",
    "            # Amount of traffic from the route from s to d\n",
    "            route_rates = np.array([\n",
    "                rates_per_state[state]\n",
    "                for state in itertools.islice(\n",
    "                    generate_states_continuous(initial_state, q_matrix),\n",
    "                    horizon\n",
    "                )\n",
    "            ])\n",
    "\n",
    "            for e in shortest_paths[(s, d)]:\n",
    "                s_, d_ = edges[e]\n",
    "                rates[s_] += route_rates\n",
    "                rates[d_] += route_rates\n",
    "\n",
    "    return rates / np.amax(rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 2\n",
    "horizon = days * 24 + 1  # Number of measurements we're taking\n",
    "t = np.linspace(0., days, horizon)\n",
    "q_matrix = np.array([\n",
    "    [-0.05, 0.05],\n",
    "    [0.2, -0.2]\n",
    "])\n",
    "\n",
    "rates_source = generate_relative_rates(horizon, n_vertices, 0, q_matrix, [1./3., 3./4.])\n",
    "rates_destination = generate_relative_rates(horizon, n_vertices, 0, q_matrix, [1./3., 3./4.])\n",
    "\n",
    "# rates_source = rates_destination = generate_relative_rates_pathwise(\n",
    "#     horizon, n_vertices, edge_to_label, all_pairs_shortest_paths, 0, q_matrix, [1./3., 3./4.]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elliptic_theta = np.vectorize(mpmath.jtheta, 'D')\n",
    "\n",
    "def get_volume(t):\n",
    "    \"\"\"\n",
    "    Generate the total amount of traffic in a system at a time of day\n",
    "    ranging from 0 to 1. The output also lies in [0, 1].\n",
    "    \"\"\"\n",
    "    mus = [9./24., 14./24., 19./24.]\n",
    "    sigmas = [0.1, 0.1, 0.1]\n",
    "    # TODO: Add some random noise\n",
    "    volume = np.real(1. + sum([\n",
    "        np.sqrt(np.pi) * sigma * elliptic_theta(3, np.pi * (mu - t), np.exp(-(np.pi * sigma)**2))\n",
    "        for mu, sigma in zip(mus, sigmas)\n",
    "    ]) / len(mus))\n",
    "    return volume / np.amax(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = get_volume(t)\n",
    "plt.plot(t, volume)\n",
    "plt.ylim(bottom=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, in a 2 day period, traffic on a link from s to d at\n",
    "# time t is given by\n",
    "# rates_source[s, t] * rates_destination[d, t] * volume[t]\n",
    "\n",
    "def estimate_delays_single_link(s, d, rates_source, rates_destination, volume, mu=1., c=1.):\n",
    "    \"\"\"\n",
    "    Estimate delay given traffic.\n",
    "\n",
    "    `mu` is the delay of the link under no load. `c` is a parameter\n",
    "    controlling how much load should affect delay (higher = less\n",
    "    effect).\n",
    "    \"\"\"\n",
    "    return mu / (1 - rates_source[s, :] * rates_destination[d, :] * volume / c)\n",
    "\n",
    "def estimate_delays(s, d, all_pairs_shortest_paths, delays_single_link):\n",
    "    return sum(\n",
    "        [\n",
    "            delays_single_link[edge]\n",
    "            for edge in all_pairs_shortest_paths[(s, d)]\n",
    "        ],\n",
    "        np.zeros(delays_single_link[0].shape)\n",
    "    ) + sum(\n",
    "        [\n",
    "            delays_single_link[edge]\n",
    "            for edge in all_pairs_shortest_paths[(d, s)]\n",
    "        ],\n",
    "        np.zeros(delays_single_link[0].shape)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_delays_single_link = [\n",
    "    estimate_delays_single_link(\n",
    "        s, d,\n",
    "        rates_source, rates_destination,\n",
    "        volume,\n",
    "        utility.get_GCL(\n",
    "            (v_s['lat'], v_s['long']),\n",
    "            (v_d['lat'], v_d['long'])\n",
    "        ),\n",
    "        5.\n",
    "    )\n",
    "    for (s, d) in edge_to_label\n",
    "    for v_s in (graph.nodes[vertex_to_label[s]],)\n",
    "    for v_d in (graph.nodes[vertex_to_label[d]],)\n",
    "]\n",
    "estimated_delays = {\n",
    "    (s, d): estimate_delays(s, d, all_pairs_shortest_paths, estimated_delays_single_link)\n",
    "    for s in range(n_vertices)\n",
    "    for d in range(n_vertices)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (s, d), estimated_delays_vector in estimated_delays.items():\n",
    "    if s == d:\n",
    "        continue\n",
    "    v_s = graph.nodes[vertex_to_label[s]]\n",
    "    v_d = graph.nodes[vertex_to_label[d]]\n",
    "    gcl = utility.get_GCL(\n",
    "        (v_s['lat'], v_s['long']),\n",
    "        (v_d['lat'], v_d['long'])\n",
    "    )\n",
    "    plt.plot(estimated_delays_vector - gcl)\n",
    "plt.title('Residual Latencies vs. Time')\n",
    "plt.ylabel('Residual Latency')\n",
    "plt.xlabel('Time')\n",
    "plt.ylim(bottom=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(horizon):\n",
    "    with open(os.path.join('..', 'data', 'toy', 'generated', 'latencies', f'{i}.csv'), 'w') as f:\n",
    "        writer = csv.DictWriter(f, ['source_id', 'target_id', 'rtt'])\n",
    "        writer.writeheader()\n",
    "        for (s, d), delays in estimated_delays.items():\n",
    "            writer.writerow({\n",
    "                'source_id': vertex_to_label[s],\n",
    "                'target_id': vertex_to_label[d],\n",
    "                'rtt': delays[i],\n",
    "                # 'rtt': min(estimated_delays[(s, d)][i], estimated_delays[(d, s)][i])\n",
    "            })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d89b9b29506d1129e078cbafd5718f53824d76c4e79258120e482e59221da99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
