{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d069f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import potpourri3d as pp3d\n",
    "\n",
    "sys.path.append(str(pathlib.PurePath('..', '..', 'src')))\n",
    "from linear_geodesic_optimization.data import utility\n",
    "from linear_geodesic_optimization.graph import boundary\n",
    "from linear_geodesic_optimization.mesh.rectangle import Mesh as RectangleMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9968dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs are stored in `directory_outputs` / <output number> / `subdirectory_output`\n",
    "epsilon = 7\n",
    "directory_data = pathlib.PurePath('..')\n",
    "directory_outputs = pathlib.PurePath('..', '..', 'outputs', 'esnet_windowed')\n",
    "subdirectory_output = pathlib.PurePath(f'{epsilon}_0.0002_50_50')\n",
    "directories_outputs = list(sorted([\n",
    "    (\n",
    "        float(directory_output),\n",
    "        directory_outputs / directory_output / subdirectory_output,\n",
    "    )\n",
    "    for i, directory_output in enumerate(sorted(os.listdir(directory_outputs)))\n",
    "    if os.path.isdir(directory_outputs / directory_output)\n",
    "]))\n",
    "\n",
    "directory_links_standin = pathlib.PurePath('esnet', 'links')\n",
    "\n",
    "directory_output_images = pathlib.PurePath('..', '..', 'outputs', 'images', 'postprocessed_intercept')\n",
    "directory_output_csvs = pathlib.PurePath('..', '..', 'outputs', 'csvs')\n",
    "\n",
    "height_scale = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b86ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_vertex(mesh: RectangleMesh, vertex):\n",
    "    \"\"\"\n",
    "    Find the xy-coordinates of the nearest mesh point to some coordinates.\n",
    "    \"\"\"\n",
    "    nearest_vertex = mesh.get_coordinates()[mesh.nearest_vertex(vertex).index]\n",
    "    return [nearest_vertex[0], nearest_vertex[1]]\n",
    "\n",
    "def compute_geodesics_from_graph(mesh: RectangleMesh, network_vertices, network_edges, geodesic_index_pairs):\n",
    "    mesh_scale = mesh.get_scale()\n",
    "\n",
    "    network_indices = set()\n",
    "    bad_indices = set()\n",
    "    for (index_source, index_target) in geodesic_index_pairs:\n",
    "        network_indices.add(index_source)\n",
    "        network_indices.add(index_target)\n",
    "    for network_index in network_indices:\n",
    "        network_vertex = network_vertices[network_index]\n",
    "        if network_vertex.tolist() not in (mesh.get_coordinates()[:, :2].tolist()):\n",
    "            try:\n",
    "                mesh.add_vertex_at_coordinates(network_vertex)\n",
    "            except ValueError:\n",
    "                bad_indices.add(network_index)\n",
    "\n",
    "    path_solver = pp3d.EdgeFlipGeodesicSolver(\n",
    "        mesh.get_coordinates(),\n",
    "        np.array([\n",
    "            [vertex.index for vertex in face.vertices()]\n",
    "            for face in mesh.get_topology().faces()\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    geodesics = []\n",
    "    for (index_source, index_target) in geodesic_index_pairs:\n",
    "        if index_source in bad_indices or index_target in bad_indices:\n",
    "            continue\n",
    "\n",
    "        source = mesh.nearest_vertex(network_vertices[index_source]).index\n",
    "        target = mesh.nearest_vertex(network_vertices[index_target]).index\n",
    "\n",
    "        if source == target:\n",
    "            continue\n",
    "        else:\n",
    "            geodesic = path_solver.find_geodesic_path(source, target)\n",
    "            geodesics.append((geodesic[:, :2] / mesh_scale).tolist())\n",
    "\n",
    "    return geodesics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the data from the files\n",
    "outputs = []\n",
    "times = []\n",
    "for t, directory_output in directories_outputs:\n",
    "    with open(directory_output / 'output.json', 'r') as file_output:\n",
    "        outputs.append(json.load(file_output))\n",
    "        times.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering should always return the same set of clusters, but we might\n",
    "# end up omiting nodes that have no associated measurements at a\n",
    "# snapshot. We might also choose a different cluster representative.\n",
    "# So, we need to ensure our network vertices are uniform across time.\n",
    "\n",
    "# Determine a consistent set of cluster representatives, their\n",
    "# coordinates, and their associated data\n",
    "node_labels_to_representatives = {}\n",
    "node_representatives_to_labels = {}\n",
    "node_labels_to_coordinates = {}\n",
    "node_labels_to_data = {}\n",
    "node_data_keys = set()\n",
    "for output in outputs:\n",
    "    network = output['network']\n",
    "    graph_data, vertex_data, edge_data = network\n",
    "\n",
    "    # Cases depending on whether clustering was used\n",
    "    if 'elements' in vertex_data:\n",
    "        for index, (node_label, elements, coordinates) in enumerate(zip(graph_data['labels'], vertex_data['elements'], graph_data['coordinates'])):\n",
    "            node_representative = min(elements)\n",
    "            for element in elements:\n",
    "                node_labels_to_representatives[element] = node_representative\n",
    "            node_labels_to_coordinates[node_representative] = coordinates\n",
    "            node_labels_to_data[node_representative] = {\n",
    "                key: value[index]\n",
    "                for key, value in vertex_data.items()\n",
    "            }\n",
    "    else:\n",
    "        for index, (node_label, coordinates) in enumerate(zip(graph_data['labels'], graph_data['coordinates'])):\n",
    "            node_labels_to_representatives[node_label] = node_label\n",
    "            node_labels_to_coordinates[node_label] = coordinates\n",
    "            node_labels_to_data[node_label] = {\n",
    "                key: value[index]\n",
    "                for key, value in vertex_data.items()\n",
    "            }\n",
    "\n",
    "    for key in vertex_data.keys():\n",
    "        node_data_keys.add(key)\n",
    "\n",
    "node_indices_to_labels = list(sorted(node_labels_to_coordinates))\n",
    "node_labels_to_indices = {label: index for index, label in enumerate(node_indices_to_labels)}\n",
    "for node_label, node_representative in node_labels_to_representatives.items():\n",
    "    node_labels_to_indices[node_label] = node_labels_to_indices[node_representative]\n",
    "for node_label, node_representative in node_labels_to_representatives.items():\n",
    "    if node_representative not in node_representatives_to_labels:\n",
    "        node_representatives_to_labels[node_representative] = [node_label]\n",
    "    else:\n",
    "        node_representatives_to_labels[node_representative].append(node_label)\n",
    "\n",
    "# Combine the computed data into an appropriate format\n",
    "node_labels = node_indices_to_labels\n",
    "node_coordinates = [node_labels_to_coordinates[label] for label in node_labels]\n",
    "node_data = {\n",
    "    key: [\n",
    "        node_labels_to_data[label][key] if key in node_labels_to_data[label] else None\n",
    "        for label in node_labels\n",
    "    ]\n",
    "    for key in node_data_keys\n",
    "}\n",
    "\n",
    "# Relabel the networks\n",
    "for output in outputs:\n",
    "    network = output['network']\n",
    "    graph_data, vertex_data, edge_data = network\n",
    "\n",
    "    graph_data_new = {\n",
    "        'coordinates': node_coordinates,\n",
    "        'edges': [\n",
    "            (node_labels_to_indices[source_label], node_labels_to_indices[target_label])\n",
    "            for source_index, target_index in graph_data['edges']\n",
    "            for source_label in (graph_data['labels'][source_index],)\n",
    "            for target_label in (graph_data['labels'][target_index],)\n",
    "        ],\n",
    "        'labels': node_indices_to_labels,\n",
    "        'bounding_box': graph_data['bounding_box'] if 'bounding_box' in graph_data else None\n",
    "    }\n",
    "    vertex_data_new = node_data\n",
    "    edge_data_new = edge_data\n",
    "\n",
    "    output['network'] = (graph_data_new, vertex_data_new, edge_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the z-coordinates across time\n",
    "zs = []\n",
    "for output in outputs:\n",
    "    z = np.array(output['final']) - np.array(output['initial'])\n",
    "    zs.append(z - np.mean(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume most parameters don't change across snapshots\n",
    "parameters = outputs[0]['parameters']\n",
    "width = parameters['width']\n",
    "height = parameters['height']\n",
    "mesh_scale = parameters['mesh_scale']\n",
    "coordinates_scale = parameters['coordinates_scale']\n",
    "mesh = RectangleMesh(width, height, mesh_scale)\n",
    "\n",
    "# Assume bounding box information is constant\n",
    "graph_data, vertex_data, edge_data = outputs[0]['network']\n",
    "bounding_box = graph_data['bounding_box']\n",
    "network_vertices = mesh.map_coordinates_to_support(np.array(node_coordinates), coordinates_scale, bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the network borders\n",
    "borders = []\n",
    "distances_to_borders = []\n",
    "for output in outputs:\n",
    "    network = output['network']\n",
    "    graph_data, vertex_data, edge_data = network\n",
    "\n",
    "    network_edges = graph_data['edges']\n",
    "    network_border = boundary.compute_border(network_vertices, network_edges)\n",
    "    distances_to_borders.append(np.array([\n",
    "        boundary.distance_to_border(\n",
    "            np.array(vertex_coordinate),\n",
    "            network_border\n",
    "        )\n",
    "        for vertex_coordinate in mesh.get_coordinates()[:, :2]\n",
    "    ]))\n",
    "    borders.append(np.where(distances_to_borders[-1] == 0.)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9b0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine values for vertical scaling\n",
    "z_max = -np.inf\n",
    "z_min = np.inf\n",
    "for z, hull in zip(zs, borders):\n",
    "    z_max = max(z_max, np.max(z[hull]))\n",
    "    z_min = min(z_min, np.min(z[hull]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43dbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_data = []\n",
    "for t, output, z, distance_to_network in zip(times, outputs, zs, distances_to_borders):\n",
    "    z_original = np.copy(z)\n",
    "    parameters = output['parameters']\n",
    "    filename_links = pathlib.PurePath(parameters['filename_links'])\n",
    "\n",
    "    if directory_links_standin is not None:\n",
    "        filename_links = directory_links_standin / filename_links.name\n",
    "\n",
    "    # Postprocess\n",
    "    hull = [index for index in range(mesh.get_topology().n_vertices) if distance_to_network[index] < 0.025]\n",
    "    distance_to_network = np.maximum(distance_to_network - 0.025, 0.)\n",
    "    z = z - z_min\n",
    "    z = z / (z_max - z_min) * height_scale\n",
    "    z = (z + 0.05) * np.exp(-1000 * distance_to_network**2) - 0.05\n",
    "\n",
    "    mesh.set_parameters(z)\n",
    "    mesh.trim_to_set(hull)\n",
    "\n",
    "    path_solver = pp3d.EdgeFlipGeodesicSolver(\n",
    "        mesh.get_coordinates(),\n",
    "        np.array([\n",
    "            [vertex.index for vertex in face.vertices()]\n",
    "            for face in mesh.get_topology().faces()\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    with open(directory_data / filename_links, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        geodesics_data = {}\n",
    "        for row in reader:\n",
    "            key = (row['source_id'], row['target_id'])\n",
    "\n",
    "            network_edge = (\n",
    "                node_labels_to_indices[key[0]],\n",
    "                node_labels_to_indices[key[1]]\n",
    "            )\n",
    "            vertex_source = mesh.nearest_vertex(network_vertices[network_edge[0]])\n",
    "            vertex_target = mesh.nearest_vertex(network_vertices[network_edge[1]])\n",
    "            geodesic_path = path_solver.find_geodesic_path(vertex_source.index, vertex_target.index) if vertex_source.index != vertex_target.index else [mesh.get_coordinates()[vertex_source.index]]\n",
    "            geodesic_distance = sum([np.linalg.norm(u - v) for u, v in itertools.pairwise(geodesic_path)], 0.)\n",
    "\n",
    "            row['geodesic_distance'] = geodesic_distance\n",
    "            geodesics_data[key] = row\n",
    "    links_data.append(geodesics_data)\n",
    "\n",
    "    mesh.restore_removed_vertices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([row['geodesic_distance'] for geodesics_data in links_data for row in geodesics_data.values() if row['rtt']])\n",
    "y = np.array([float(row['rtt']) for geodesics_data in links_data for row in geodesics_data.values() if row['rtt']])\n",
    "plt.plot(x, y, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, c = np.linalg.lstsq(\n",
    "    np.vstack([x, np.ones(len(x))]).T,\n",
    "    y\n",
    ")[0]\n",
    "# m = np.linalg.lstsq(x.reshape((-1, 1)), y)[0]\n",
    "# c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66555398",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set(\n",
    "    key\n",
    "    for geodesics_data in links_data\n",
    "    for key in geodesics_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218cca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write time series plots\n",
    "# for key in keys:\n",
    "#     geodesics_key = np.array([geodesics_data[key]['geodesic_distance'] for geodesics_data in links_data])\n",
    "#     rtts_key = np.array([float(geodesics_data[key]['rtt']) if geodesics_data[key]['rtt'] else 0. for geodesics_data in links_data])\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1)\n",
    "#     ax.plot(m * geodesics_key + c, 'b-', label='geodesics')\n",
    "#     ax.plot(rtts_key, 'r-', label='RTTs')\n",
    "#     ax.set_title(f'{key[0]} $\\\\rightarrow$ {key[1]}')\n",
    "#     ax.legend()\n",
    "#     fig.savefig(directory_output_images / f'{key[0]}_{key[1]}.png', dpi=200)\n",
    "#     fig.clear()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write CSVs\n",
    "# for key in keys:\n",
    "#     rtts_key = [float(geodesics_data[key]['rtt']) if geodesics_data[key]['rtt'] else None for geodesics_data in links_data]\n",
    "#     geodesics_key = [geodesics_data[key]['geodesic_distance'] for geodesics_data in links_data]\n",
    "\n",
    "#     with open(directory_output_csvs / f'{min(key)}_{max(key)}.csv', 'w') as f:\n",
    "#         writer = csv.DictWriter(f, ['time', 'rtt', 'geodesic_distance', 'geodesic_distance_transformed'])\n",
    "#         writer.writeheader()\n",
    "\n",
    "#         for t, rtt, geodesic in zip(times, rtts_key, geodesics_key):\n",
    "#             writer.writerow({\n",
    "#                 'time': int(t / 1000),\n",
    "#                 'rtt': rtt,\n",
    "#                 'geodesic_distance': geodesic,\n",
    "#                 'geodesic_distance_transformed': m * geodesic + c,\n",
    "#             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtt_variations = [\n",
    "    key\n",
    "    for _, key in sorted([\n",
    "        ((np.min(rtts_key) - np.max(rtts_key)) / (np.median(rtts_key) if np.median(rtts_key) != 0. else 1.), key)\n",
    "        for key in keys\n",
    "        for rtts_key in (np.array([float(geodesics_data[key]['rtt']) if geodesics_data[key]['rtt'] else 0. for geodesics_data in links_data]),)\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512681a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in rtt_variations[:120]:\n",
    "    # print(f'{key[0]} -> {key[1]}')\n",
    "    print(f'{key},')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
